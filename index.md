<p align="justify">
Our goal is to generate a visually appealing video that responds to music with a neural network so that each frame of the video represents the musical characteristics of the corresponding audio clip. To achieve the goal, we propose a neural music visualizer directly mapping deep music embeddings to style embeddings of StyleGAN, named Tr√§umerAI
</p>


![Model Architecture Ver 5 small artboard 2](./assets/img/<main_2col class="png"></main_2col>)
<p align="center">Figure.1 System diagram and generated images from Queen's Bohemian Rhapsody</p>

### Generated Videos
<iframe width="560" height="315" src="https://www.youtube.com/embed/fmsBeOfMVtA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

</style>
